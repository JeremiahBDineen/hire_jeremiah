<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Clean Financial Data for 1500 Public Companies</title>
  <link rel="stylesheet" href="styles.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.4/css/jquery.dataTables.min.css">
  <style>
    .sec-project {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      padding: 40px;
      max-width: 1000px;
      margin: auto;
    }
    .sec-project h1, .sec-project h2, .sec-project h3 {
      border-bottom: 1px solid #ccc;
      padding-bottom: 0.25rem;
    }
    .sec-project code {
      background: #f4f4f4;
      padding: 2px 4px;
      border-radius: 4px;
    }
    .sec-project pre code {
      font-size: 0.9rem;
    }
    .sec-project pre {
      background: #f4f4f4;
      padding: 1rem;
      overflow-x: auto;
      border-radius: 6px;
    }
    .sec-project details summary {
      cursor: pointer;
      font-weight: bold;
      margin-top: 1rem;
    }
  </style>
</head>
<body>
<header><nav>
  <ul class="navbar">
    <li><a href="index.html">Home</a></li>
    <li><a href="about.html">About Me</a></li>
    <li><a href="SEC_Data_Project.html">SEC_Data_Project</a></li>
    <li class="dropdown"><a href="eua_population.html" class="dropbtn">Exploratory Univariate Analysis</a>
      <div class="dropdown-content">
        <a href="eua_population.html">Population</a>
        <a href="eua_median_income.html">Median Income</a>
        <a href="eua_mean_income.html">Mean Income</a>
        <a href="eua_house_price.html">House Price</a>
        <a href="eua_home_affordability.html">Home Affordability</a>
      </div>
    </li>
    <li class="dropdown"><a href="ima_median_income_vs_household_count.html" class="dropbtn">Inferential Multivariate Analysis</a>
      <div class="dropdown-content">
        <a href="ima_median_income_vs_household_count.html">association - median income + household count</a>
        <a href="ima_house_price_vs_median_income.html">association - house price + median income</a>
      </div>
    </li>
    <li><a href="tableau_map.html">Tableau Map</a></li>
    <li class="dropdown"><a href="code_us_county_data.html" class="dropbtn">Code</a>
      <div class="dropdown-content">
        <a href="code_us_county_data.html">us_county_data_python</a>
        <a href="code_us_county_data_R.html">us_county_data_R</a>
        <a href="code_tigris_data.html">tigris_data</a>
        <a href="code_eua_population.html">eua_population</a>
        <a href="code_eua_median_income.html">eua_median_income</a>
        <a href="code_eua_mean_income.html">eua_mean_income</a>
        <a href="code_eua_house_price.html">eua_house_price</a>
        <a href="code_eua_home_affordability.html">eua_home_affordability</a>
        <a href="code_ima_median_income_vs_household_count.html">ima_median_income_vs_household_count</a>
        <a href="code_ima_house_price_vs_median_income.html">ima_house_price_vs_median_income</a>
      </div>
    </li>
    <li><a href="cv.html">CV</a></li>
  </ul>
</nav></header>
<main class="sec-project">
<h1>Clean Financial Data for 1500 Public Companies</h1>
<p><strong>A Python-powered pipeline to convert 15,000+ SEC filings into a single, unified, structured, analysis-ready table ‚Äî no vendor, no manual effort.</strong></p>

<h2>üìà Project Stats</h2>
<ul>
  <li><strong>Total rows:</strong> 12.8 million</li>
  <li><strong>Companies:</strong> 1,438 public tickers</li>
  <li><strong>GAAP measures:</strong> 9,556 unique fields</li>
  <li><strong>Years covered:</strong> 1980 ‚Äì 2025 (primarily 2003‚Äì2023)</li>
  <li><strong>Filings:</strong> 7.2M 10-Qs, 5.3M 10-Ks, + others</li>
  <li><strong>Unique period filings:</strong> 77,694 unique (ticker √ó year √ó period)</li>
  <li><strong>Total script length:</strong> 100 lines of Python</li>
</ul>

<h2>üìä Sample Output: Microsoft (MSFT), FY 2024</h2>
<section>
  <pre><code class="language-sql">SELECT * FROM sec_data_project WHERE ticker = 'msft' AND fy = '2024';</code></pre>
  <div style="overflow-x: auto; max-height: 500px;">
    <table id="populationTable" class="display" style="width:100%">
      <thead><tr></tr></thead>
      <style>
  #populationTable th:nth-child(2) {
    max-width: 150px;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
  }
</style>
      <tbody></tbody>
    </table>
  </div>
</section>

<p><a href="output/tables/msft_2024_table.csv">Download CSV</a></p>

<h2>‚öôÔ∏è How It Works</h2>
<ol>
  <li><strong>Collect Tickers + SEC Identifiers:</strong><br>Use Wikipedia to identify the full SP1500 universe, and join with the official CIK registry.</li><br>
  <li><strong>Query the SEC‚Äôs API:</strong><br>For each company, collect all filings (10-Ks, 10-Qs) using the SEC‚Äôs public JSON endpoint.</li><br>
  <li><strong>Flatten and Clean:</strong><br>Flatten nested JSON entries, standardize formats, and join into a single master dataset.</li>
</ol>

<h2>üõ†Ô∏è Key Data Skills Demonstrated</h2>
<ul>
  <li>Data acquisition via API and web scraping across multiple sources (Wikipedia, SEC)</li>
  <li>Large-scale ingestion and parsing of deeply nested JSON structures (15,000+ filings)</li>
  <li>Data wrangling: subsetting, reshaping, binding, type coercion, joins, deduplication</li>
  <li>Standardizing metadata and temporal fields for downstream aggregation</li>
  <li>Reformatting, filtering, and validating missing or null entries</li>
  <li>Multi-source joining and reconciliation of mismatched identifier fields</li>
  <li>Writing intermediary modular artifacts and exporting platform-independent output (CSV, Parquet)</li>
  <li>Clean, succinct, modular code</li>
</ul>

<h2>üíª Full Script (100 lines)</h2>
<pre><code class="language-python">
import pandas as pd
import requests
import time
import json

sp500 = pd.read_html("https://en.wikipedia.org/wiki/List_of_S%26P_500_companies")[0][["Symbol", "Security"]]
sp400 = pd.read_html("https://en.wikipedia.org/wiki/List_of_S%26P_400_companies")[0][["Symbol", "Security"]]
sp600 = pd.read_html("https://en.wikipedia.org/wiki/List_of_S%26P_600_companies")[0][["Symbol", "Company"]]
sp600.columns = ["Symbol", "Security"]

sp1500 = pd.concat([sp500, sp400, sp600], ignore_index=True)
sp1500["ticker"] = sp1500["Symbol"].str.lower()
sp1500 = sp1500[["ticker", "Security"]]
sp1500.columns = ["ticker", "company"]

cik = requests.get("https://www.sec.gov/include/ticker.txt", headers={"User-Agent": "jeremiahbdineen@gmail.com"}).text.strip().split("\n")
cik = pd.DataFrame([line.split("\t") for line in cik], columns=["ticker", "cik"])
cik["cik"] = cik["cik"].str.zfill(10)

sp1500 = sp1500.merge(cik, on="ticker", how="left")
sp1500 = sp1500[sp1500["cik"].notna()].copy()

def fetch_company_facts(cik):
    cik_padded = str(cik).zfill(10)
    url = f"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik_padded}.json"
    headers = {"User-Agent": "jeremiahbdineen@gmail.com"}

    try:
        res = requests.get(url, headers=headers, timeout=10)
        if res.status_code != 200:
            return None
        return res.json()
    except Exception as e:
        print(f"Error fetching {cik_padded}: {e}")
        return None

company_facts = []

for i, row in sp1500.iterrows():
    cik = row["cik"]
    print(f"Fetching {row['ticker']} ({cik}) ... ", end="")
    facts = fetch_company_facts(cik)
    company_facts.append(facts)
    print("‚úî" if facts else "‚úò")
    time.sleep(3)  
sp1500["company_facts"] = company_facts

#save intermediary data structure (sp1500 df with json nested column)
sp1500.to_pickle("data/sp1500.pkl")
sp1500 = pd.read_pickle("data/sp1500.pkl")

def extract_us_gaap_values(ticker, company_facts):
    try:
        us_gaap = company_facts["facts"]["us-gaap"]
    except (KeyError, TypeError):
        return pd.DataFrame()

    rows = []

    for measure, entry in us_gaap.items():
        if "units" not in entry:
            continue

        for unit, values in entry["units"].items():
            if not isinstance(values, list):
                continue

            for record in values:
                if not all(k in record for k in ["val", "end", "fy", "fp", "filed", "accn", "form", "frame"]):
                    continue

                rows.append({
                    "ticker": ticker,
                    "measure": measure,
                    "unit": unit,
                    "val": record["val"],
                    "end": record["end"],
                    "fy": record["fy"],
                    "fp": record["fp"],
                    "filed": record["filed"],
                    "accn": record["accn"],
                    "form": record["form"],
                    "frame": record["frame"]
                })

    return pd.DataFrame(rows)

records = []

for i, row in sp1500.iterrows():
    extracted = extract_us_gaap_values(row["ticker"], row["company_facts"])
    if not extracted.empty:
        records.append(extracted)

us_gaap = pd.concat(records, ignore_index=True)
us_gaap["end"] = pd.to_datetime(us_gaap["end"], errors="coerce")
us_gaap["filed"] = pd.to_datetime(us_gaap["filed"], errors="coerce")

us_gaap.to_parquet("data/us_gaap.parquet", index=False)
us_gaap.to_csv("data/us_gaap.csv", index=False)
</code></pre>
</main>
<script src="https://cdn.jsdelivr.net/npm/papaparse@5.4.1/papaparse.min.js"></script>
<script src="https://code.jquery.com/jquery-3.7.0.min.js"></script>
<script src="https://cdn.datatables.net/1.13.4/js/jquery.dataTables.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
<script>
  fetch('output/tables/msft_2024_table.csv')
    .then(response => response.text())
    .then(csvText => {
      const parsed = Papa.parse(csvText, {
        header: true,
        skipEmptyLines: true
      });

      const headers = parsed.meta.fields;
      const rows = parsed.data;

      const thead = document.querySelector('#populationTable thead tr');
      headers.forEach(h => {
        const th = document.createElement('th');
        th.textContent = h;
        thead.appendChild(th);
      });

      const tbody = document.querySelector('#populationTable tbody');
      rows.forEach(row => {
        const tr = document.createElement('tr');
        headers.forEach(h => {
          const td = document.createElement('td');
          td.textContent = row[h];
          tr.appendChild(td);
        });
        tbody.appendChild(tr);
      });

      new DataTable('#populationTable', {
        scrollY: '400px',
        scrollCollapse: true,
        paging: true,
        pageLength: 25,
        ordering: false
      });
    });
</script>
</body>
</html>
